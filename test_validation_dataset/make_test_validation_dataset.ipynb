{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "\n",
    "test_dataset = load_from_disk('/opt/ml/data/test_dataset')\n",
    "test_dataset = test_dataset['validation']\n",
    "\n",
    "test_data = []\n",
    "\n",
    "for i, row in enumerate(test_dataset):\n",
    "    test_data.append(row)\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_df['test_id_no'] = test_df['id'].apply(lambda x: x.split('-')[-1])\n",
    "\n",
    "def get_klue_df(df, data_source):\n",
    "    data_objs = {\n",
    "        'version': [],\n",
    "        'title': [],\n",
    "        'context': [],\n",
    "        'question': [],\n",
    "        'answer_text': [],\n",
    "        'answer_start': [],\n",
    "        'question_type': [],\n",
    "        'is_impossible': [],\n",
    "        'guid': [],\n",
    "        'klue_id_no': [],\n",
    "        'news_category': [],\n",
    "        'source': [],\n",
    "        'data_source': []\n",
    "    }\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        data = row['data']\n",
    "        qas = data['paragraphs'][0]['qas']\n",
    "        for q in qas:\n",
    "            if len(q['answers']) == 0:\n",
    "                continue\n",
    "            data_objs['version'].append(row['version'])\n",
    "            data_objs['title'].append(data['title'])\n",
    "            data_objs['context'].append(data['paragraphs'][0]['context'])\n",
    "            data_objs['question'].append(q['question'])\n",
    "            answer_text_list = []\n",
    "            answer_start_list = []\n",
    "            for ans in q['answers']:\n",
    "                answer_text_list.append(ans['text'])\n",
    "                answer_start_list.append(ans['answer_start'])\n",
    "            # data_objs['answer_text'].append(q['answers'][0]['text'])\n",
    "            # data_objs['answer_start'].append(q['answers'][0]['answer_start'])\n",
    "            data_objs['answer_text'].append(answer_text_list)\n",
    "            data_objs['answer_start'].append(answer_start_list)        \n",
    "            data_objs['question_type'].append(q['question_type'])\n",
    "            data_objs['is_impossible'].append(q['is_impossible'])\n",
    "            data_objs['guid'].append(q['guid'])\n",
    "            data_objs['klue_id_no'].append(q['guid'].split('_')[-1])\n",
    "            data_objs['news_category'].append(data['news_category'])\n",
    "            data_objs['source'].append(data['source'])\n",
    "            data_objs['data_source'].append(data_source)\n",
    "\n",
    "    return pd.DataFrame(data_objs)\n",
    "\n",
    "klue_train_df = get_klue_df(pd.read_json('./klue-mrc-v1.1_train.json'), 'train')\n",
    "klue_dev_df = get_klue_df(pd.read_json('./klue-mrc-v1.1_dev.json'), 'dev')\n",
    "\n",
    "klue_df = pd.concat([klue_train_df, klue_dev_df])\n",
    "\n",
    "merge_df = pd.merge(test_df, klue_df, how='outer', on='question')\n",
    "merge_df['id'].fillna('miss', inplace=True)\n",
    "merge_df['answer_text'].fillna('none', inplace=True)\n",
    "merge_df = merge_df.loc[merge_df['id'] != 'miss', :]\n",
    "merge_df = merge_df.loc[merge_df['answer_text'] != 'none', :]\n",
    "merge_df['answer_text'] = merge_df['answer_text'].apply(lambda x: x[0])\n",
    "merge_df['answer_start'] = merge_df['answer_start'].apply(lambda x: x[0])\n",
    "merge_df.to_csv('test_merge_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>title</th>\n",
       "      <th>document_id</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mrc-1-000653</td>\n",
       "      <td>유령'은 어느 행성에서 지구로 왔는가?</td>\n",
       "      <td>더크 젠틀리의 성스러운 탐정사무소의 줄거리는 이야기의 중추적인 부위에 자리잡은 시간...</td>\n",
       "      <td>더크 젠틀리의 성스러운 탐정 사무소</td>\n",
       "      <td>0</td>\n",
       "      <td>{'answer_start': [88], 'text': ['사락사라']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mrc-1-001113</td>\n",
       "      <td>용병회사의 경기가 좋아진 것은 무엇이 끝난 이후부터인가?</td>\n",
       "      <td>냉전 종식 이후 전 세계적으로 소규모의 끊임없는 국지 분쟁들이 생겨나고 강대국들의 ...</td>\n",
       "      <td>오퍼레이션7</td>\n",
       "      <td>1</td>\n",
       "      <td>{'answer_start': [0], 'text': ['냉전']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mrc-0-002191</td>\n",
       "      <td>돌푸스에게 불특정 기간동안 하원이 잠시 쉬는 것을 건의 받았던 인물은?</td>\n",
       "      <td>1933년 3월, 투표 과정의 위법성에 대한 문제제기가 불거졌다. 당시 오스트리아 ...</td>\n",
       "      <td>엥겔베르트 돌푸스</td>\n",
       "      <td>2</td>\n",
       "      <td>{'answer_start': [253], 'text': ['빌헬름 미클라스']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mrc-1-001272</td>\n",
       "      <td>디엔비엔푸 전투에서 보응우옌잡이 상대한 국가는?</td>\n",
       "      <td>1926년 학생 시절 베트남청년혁명당에 가입했고 1930년에 학생 파업을 지지했다는...</td>\n",
       "      <td>보응우옌잡</td>\n",
       "      <td>3</td>\n",
       "      <td>{'answer_start': [771], 'text': ['프랑스']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mrc-1-000993</td>\n",
       "      <td>단공류가 일반 포유류와 다르다는 것을 알 수 있는 신체 부위는?</td>\n",
       "      <td>단공류는 포유류의 극히 적은 부분이다. 멸종된 단공류를 제외하면, 여기에 해당하는 ...</td>\n",
       "      <td>단공류</td>\n",
       "      <td>4</td>\n",
       "      <td>{'answer_start': [576], 'text': ['뒷다리']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>mrc-0-000651</td>\n",
       "      <td>디즈니랜드에서 개인회원을 뽑기 시작한 년도는?</td>\n",
       "      <td>1962년부터 1965년까지의 뉴욕 세계 박람회에서 다양한 기업 창설자들과 어트랙션...</td>\n",
       "      <td>클럽 33</td>\n",
       "      <td>470</td>\n",
       "      <td>{'answer_start': [348], 'text': ['1967년']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>mrc-0-002989</td>\n",
       "      <td>타입 2 가이아 메모리을 만든 집단은?</td>\n",
       "      <td>재단 X가 슈라우드(=소노자키 후미네)가 개발한 가이아 메모리의 테크놀로지를 분석,...</td>\n",
       "      <td>극장판 가면라이더 W FOREVER: A to Z/운명의 가이아 메모리</td>\n",
       "      <td>471</td>\n",
       "      <td>{'answer_start': [0], 'text': ['재단 X']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>mrc-0-003411</td>\n",
       "      <td>콜드게임 중 어떠한 계기로 인해 잠시 중단된 뒤, 익일에 게임이 진행되는 것은?</td>\n",
       "      <td>콜드게임(called game)이란 야구나 소프트볼 등의 운동경기에서 심판에 의하여...</td>\n",
       "      <td>콜드게임</td>\n",
       "      <td>472</td>\n",
       "      <td>{'answer_start': [492], 'text': ['서스펜디드 게임']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>mrc-0-003436</td>\n",
       "      <td>제2캐나다기갑여단이 상륙한 곳은?</td>\n",
       "      <td>주노 해변\\n\\n주노 해변은 쿠르쇨르메르의 양쪽으로 뻗은 5마일 정도의 해변이었다....</td>\n",
       "      <td>제3캐나다사단</td>\n",
       "      <td>473</td>\n",
       "      <td>{'answer_start': [7], 'text': ['주노 해변']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>mrc-0-002605</td>\n",
       "      <td>구립운석을 이루는 물질 중 널리 알려진 것은?</td>\n",
       "      <td>구립운석(球粒隕石, 콘드라이트)는 석질운석의 일종으로, 운석의 원석이 용융이나 분화...</td>\n",
       "      <td>구립운석</td>\n",
       "      <td>474</td>\n",
       "      <td>{'answer_start': [137], 'text': ['수수께끼의 콘드률']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                      question  \\\n",
       "0    mrc-1-000653                         유령'은 어느 행성에서 지구로 왔는가?   \n",
       "1    mrc-1-001113               용병회사의 경기가 좋아진 것은 무엇이 끝난 이후부터인가?   \n",
       "2    mrc-0-002191       돌푸스에게 불특정 기간동안 하원이 잠시 쉬는 것을 건의 받았던 인물은?   \n",
       "3    mrc-1-001272                    디엔비엔푸 전투에서 보응우옌잡이 상대한 국가는?   \n",
       "4    mrc-1-000993           단공류가 일반 포유류와 다르다는 것을 알 수 있는 신체 부위는?   \n",
       "..            ...                                           ...   \n",
       "470  mrc-0-000651                     디즈니랜드에서 개인회원을 뽑기 시작한 년도는?   \n",
       "471  mrc-0-002989                         타입 2 가이아 메모리을 만든 집단은?   \n",
       "472  mrc-0-003411  콜드게임 중 어떠한 계기로 인해 잠시 중단된 뒤, 익일에 게임이 진행되는 것은?   \n",
       "473  mrc-0-003436                            제2캐나다기갑여단이 상륙한 곳은?   \n",
       "474  mrc-0-002605                     구립운석을 이루는 물질 중 널리 알려진 것은?   \n",
       "\n",
       "                                               context  \\\n",
       "0    더크 젠틀리의 성스러운 탐정사무소의 줄거리는 이야기의 중추적인 부위에 자리잡은 시간...   \n",
       "1    냉전 종식 이후 전 세계적으로 소규모의 끊임없는 국지 분쟁들이 생겨나고 강대국들의 ...   \n",
       "2    1933년 3월, 투표 과정의 위법성에 대한 문제제기가 불거졌다. 당시 오스트리아 ...   \n",
       "3    1926년 학생 시절 베트남청년혁명당에 가입했고 1930년에 학생 파업을 지지했다는...   \n",
       "4    단공류는 포유류의 극히 적은 부분이다. 멸종된 단공류를 제외하면, 여기에 해당하는 ...   \n",
       "..                                                 ...   \n",
       "470  1962년부터 1965년까지의 뉴욕 세계 박람회에서 다양한 기업 창설자들과 어트랙션...   \n",
       "471  재단 X가 슈라우드(=소노자키 후미네)가 개발한 가이아 메모리의 테크놀로지를 분석,...   \n",
       "472  콜드게임(called game)이란 야구나 소프트볼 등의 운동경기에서 심판에 의하여...   \n",
       "473  주노 해변\\n\\n주노 해변은 쿠르쇨르메르의 양쪽으로 뻗은 5마일 정도의 해변이었다....   \n",
       "474  구립운석(球粒隕石, 콘드라이트)는 석질운석의 일종으로, 운석의 원석이 용융이나 분화...   \n",
       "\n",
       "                                       title  document_id  \\\n",
       "0                        더크 젠틀리의 성스러운 탐정 사무소            0   \n",
       "1                                     오퍼레이션7            1   \n",
       "2                                  엥겔베르트 돌푸스            2   \n",
       "3                                      보응우옌잡            3   \n",
       "4                                        단공류            4   \n",
       "..                                       ...          ...   \n",
       "470                                    클럽 33          470   \n",
       "471  극장판 가면라이더 W FOREVER: A to Z/운명의 가이아 메모리          471   \n",
       "472                                     콜드게임          472   \n",
       "473                                  제3캐나다사단          473   \n",
       "474                                     구립운석          474   \n",
       "\n",
       "                                            answers  \n",
       "0          {'answer_start': [88], 'text': ['사락사라']}  \n",
       "1             {'answer_start': [0], 'text': ['냉전']}  \n",
       "2     {'answer_start': [253], 'text': ['빌헬름 미클라스']}  \n",
       "3          {'answer_start': [771], 'text': ['프랑스']}  \n",
       "4          {'answer_start': [576], 'text': ['뒷다리']}  \n",
       "..                                              ...  \n",
       "470      {'answer_start': [348], 'text': ['1967년']}  \n",
       "471         {'answer_start': [0], 'text': ['재단 X']}  \n",
       "472   {'answer_start': [492], 'text': ['서스펜디드 게임']}  \n",
       "473        {'answer_start': [7], 'text': ['주노 해변']}  \n",
       "474  {'answer_start': [137], 'text': ['수수께끼의 콘드률']}  \n",
       "\n",
       "[475 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "test_df = pd.read_csv('./test_merge_data.csv')\n",
    "test_df = test_df[['id', 'question' , 'context', 'answer_text', 'answer_start', 'title']]\n",
    "test_df['document_id'] = [i for i in range(len(test_df))]\n",
    "answers = []\n",
    "for i, row in test_df.iterrows():\n",
    "    answers.append({'answer_start': [row['answer_start']], 'text': [row['answer_text']]})\n",
    "test_df['answers'] = answers\n",
    "test_df.drop(columns=['answer_text', 'answer_start'], inplace=True)\n",
    "\n",
    "test_validation_dataset = Dataset.from_pandas(test_df)\n",
    "test_validation_dataset.save_to_disk('/opt/ml/data/test_validation_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
       "    num_rows: 240\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = load_from_disk('/opt/ml/data/train_dataset')\n",
    "eval_dataset = datasets['validation']\n",
    "document_id = [i for i in range()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question', 'context', 'title', 'document_id', 'answers', '__index_level_0__'],\n",
       "    num_rows: 475\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "test_validation_dataset = Dataset.from_pandas(test_df)\n",
    "test_validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_validation_dataset.save_to_disk('/opt/ml/data/test_validation_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
       "    num_rows: 475\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = load_from_disk('/opt/ml/data/test_validation_dataset')\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
       "    num_rows: 475\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk('/opt/ml/data/test_validation_dataset')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
