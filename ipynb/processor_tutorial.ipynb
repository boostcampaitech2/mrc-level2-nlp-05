{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from transformers import TrainingArguments\n",
    "from transformers.trainer_utils import set_seed, EvalPrediction\n",
    "\n",
    "import datasets\n",
    "from datasets import load_metric\n",
    "\n",
    "from arguments import DatasetArguments\n",
    "from processor import QAProcessor\n",
    "from trainer_qa import QATrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./saved\",\n",
    "    logging_dir = \"./logs\",\n",
    "\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    seed=42,\n",
    "    evaluation_strategy=\"steps\",\n",
    "\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=1,\n",
    "\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    label_smoothing_factor=0.1,\n",
    "\n",
    "    num_train_epochs=3,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "\n",
    "    log_level=\"info\",\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    "    save_steps=100,\n",
    "    save_total_limit=5,\n",
    "\n",
    "    metric_for_best_model=\"eval_exact_match\", # \"eval_loss\", \"eval_f1\"\n",
    "    greater_is_better=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_callback import TrainerCallback\n",
    "\n",
    "TrainerCallback()\n",
    "# should_eval, should_train, ... should_save, .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"klue/roberta-large\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_args = DatasetArguments(\n",
    "    dataset_path=\"/opt/ml/data\",\n",
    "    max_seq_len=512,\n",
    "    stride_len=128, \n",
    "    max_ans_len=30,\n",
    "    use_max_padding=True, # need to be removed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForQuestionAnswering: ['lm_head.decoder.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "set_seed(training_args.seed)\n",
    "# set seed before model is initialized\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_processor = QAProcessor(\n",
    "    dataset_args=dataset_args,\n",
    "    tokenizer=tokenizer,\n",
    "    concat=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /opt/ml/data/train_dataset/train/cache-2be0bd568b416eb6.arrow\n",
      "Loading cached processed dataset at /opt/ml/data/train_dataset/validation/cache-c233008588ad4978.arrow\n"
     ]
    }
   ],
   "source": [
    "train_examples = qa_processor.get_train_examples()\n",
    "eval_examples  = qa_processor.get_eval_examples()\n",
    "\n",
    "train_features = qa_processor.get_train_features()\n",
    "eval_features  = qa_processor.get_eval_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'end_positions': Value(dtype='int64', id=None),\n",
       " 'example_id': Value(dtype='string', id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'offset_mapping': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'overflow_to_sample_mapping': Value(dtype='int64', id=None),\n",
       " 'start_positions': Value(dtype='int64', id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'end_positions': Value(dtype='int64', id=None),\n",
       " 'example_id': Value(dtype='string', id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'offset_mapping': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'overflow_to_sample_mapping': Value(dtype='int64', id=None),\n",
       " 'start_positions': Value(dtype='int64', id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_features.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': Value(dtype='string', id=None),\n",
       " 'context': Value(dtype='string', id=None),\n",
       " 'question': Value(dtype='string', id=None),\n",
       " 'id': Value(dtype='string', id=None),\n",
       " 'answers': {'answer_start': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       "  'text': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)},\n",
       " 'document_id': Value(dtype='int64', id=None),\n",
       " '__index_level_0__': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_examples.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"squad\")\n",
    "\n",
    "def compute_metrics(pred: EvalPrediction):\n",
    "    return metric.compute(predictions=pred.predictions, references=pred.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = QATrainer(\n",
    "    model=model,\n",
    "    args=training_args, \n",
    "    train_dataset=train_features,\n",
    "    eval_dataset=eval_features,\n",
    "    eval_examples=eval_examples,\n",
    "    post_process_function=qa_processor.post_processing_function,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running training *****\n",
      "  Num examples = 5769\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2166\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthis-is-real\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/this-is-real/huggingface/runs/2opgrczz\" target=\"_blank\">./saved</a></strong> to <a href=\"https://wandb.ai/this-is-real/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1734' max='2166' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1734/2166 33:04 < 08:15, 0.87 it/s, Epoch 2.40/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.929100</td>\n",
       "      <td>1.697486</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>64.937169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.626900</td>\n",
       "      <td>1.546786</td>\n",
       "      <td>59.583333</td>\n",
       "      <td>68.568529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.184100</td>\n",
       "      <td>1.234544</td>\n",
       "      <td>64.166667</td>\n",
       "      <td>72.159392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.034000</td>\n",
       "      <td>1.096147</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>75.796883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.146600</td>\n",
       "      <td>1.336357</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>74.508929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.046300</td>\n",
       "      <td>1.225160</td>\n",
       "      <td>62.083333</td>\n",
       "      <td>71.115652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.038600</td>\n",
       "      <td>1.049474</td>\n",
       "      <td>61.250000</td>\n",
       "      <td>70.228761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.567600</td>\n",
       "      <td>1.694854</td>\n",
       "      <td>62.083333</td>\n",
       "      <td>72.129134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.528500</td>\n",
       "      <td>1.483064</td>\n",
       "      <td>61.250000</td>\n",
       "      <td>69.213701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.540700</td>\n",
       "      <td>1.686491</td>\n",
       "      <td>66.250000</td>\n",
       "      <td>73.684390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.640300</td>\n",
       "      <td>1.296091</td>\n",
       "      <td>61.250000</td>\n",
       "      <td>69.842338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.578100</td>\n",
       "      <td>1.257998</td>\n",
       "      <td>62.083333</td>\n",
       "      <td>71.486915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>1.476360</td>\n",
       "      <td>63.333333</td>\n",
       "      <td>72.230385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.585900</td>\n",
       "      <td>1.488572</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>73.331095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.386800</td>\n",
       "      <td>1.812643</td>\n",
       "      <td>63.333333</td>\n",
       "      <td>71.131019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.311700</td>\n",
       "      <td>1.765558</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>72.022984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.343600</td>\n",
       "      <td>2.114691</td>\n",
       "      <td>60.833333</td>\n",
       "      <td>69.713480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 351\n",
      "  Batch size = 16\n",
      "100%|██████████| 240/240 [00:01<00:00, 140.03it/s]\n",
      "Saving model checkpoint to ./saved/checkpoint-100\n",
      "Configuration saved in ./saved/checkpoint-100/config.json\n",
      "Model weights saved in ./saved/checkpoint-100/pytorch_model.bin\n",
      "Deleting older checkpoint [saved/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 351\n",
      "  Batch size = 16\n",
      "100%|██████████| 240/240 [00:01<00:00, 139.70it/s]\n",
      "Saving model checkpoint to ./saved/checkpoint-200\n",
      "Configuration saved in ./saved/checkpoint-200/config.json\n",
      "Model weights saved in ./saved/checkpoint-200/pytorch_model.bin\n",
      "Deleting older checkpoint [saved/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 351\n",
      "  Batch size = 16\n",
      "100%|██████████| 240/240 [00:01<00:00, 130.94it/s]\n",
      "Saving model checkpoint to ./saved/checkpoint-300\n",
      "Configuration saved in ./saved/checkpoint-300/config.json\n",
      "Model weights saved in ./saved/checkpoint-300/pytorch_model.bin\n",
      "Deleting older checkpoint [saved/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 351\n",
      "  Batch size = 16\n",
      "100%|██████████| 240/240 [00:01<00:00, 130.57it/s]\n",
      "Saving model checkpoint to ./saved/checkpoint-400\n",
      "Configuration saved in ./saved/checkpoint-400/config.json\n",
      "Model weights saved in ./saved/checkpoint-400/pytorch_model.bin\n",
      "Deleting older checkpoint [saved/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 351\n",
      "  Batch size = 16\n",
      "100%|██████████| 240/240 [00:01<00:00, 140.25it/s]\n",
      "Saving model checkpoint to ./saved/checkpoint-500\n",
      "Configuration saved in ./saved/checkpoint-500/config.json\n",
      "Model weights saved in ./saved/checkpoint-500/pytorch_model.bin\n",
      "Deleting older checkpoint [saved/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 351\n",
      "  Batch size = 16\n",
      "100%|██████████| 240/240 [00:01<00:00, 141.29it/s]\n",
      "Saving model checkpoint to ./saved/checkpoint-600\n",
      "Configuration saved in ./saved/checkpoint-600/config.json\n",
      "Model weights saved in ./saved/checkpoint-600/pytorch_model.bin\n",
      "Deleting older checkpoint [saved/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 351\n",
      "  Batch size = 16\n",
      "100%|██████████| 240/240 [00:01<00:00, 140.12it/s]\n",
      "Saving model checkpoint to ./saved/checkpoint-700\n",
      "Configuration saved in ./saved/checkpoint-700/config.json\n",
      "Model weights saved in ./saved/checkpoint-700/pytorch_model.bin\n",
      "Deleting older checkpoint [saved/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 351\n",
      "  Batch size = 16\n",
      "100%|██████████| 240/240 [00:01<00:00, 142.01it/s]\n",
      "Saving model checkpoint to ./saved/checkpoint-800\n",
      "Configuration saved in ./saved/checkpoint-800/config.json\n",
      "Model weights saved in ./saved/checkpoint-800/pytorch_model.bin\n",
      "Deleting older checkpoint [saved/checkpoint-300] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 351\n",
      "  Batch size = 16\n",
      "100%|██████████| 240/240 [00:01<00:00, 131.58it/s]\n",
      "Saving model checkpoint to ./saved/checkpoint-900\n",
      "Configuration saved in ./saved/checkpoint-900/config.json\n",
      "Model weights saved in ./saved/checkpoint-900/pytorch_model.bin\n",
      "Deleting older checkpoint [saved/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 351\n",
      "  Batch size = 16\n",
      "100%|██████████| 240/240 [00:01<00:00, 142.85it/s]\n",
      "Saving model checkpoint to ./saved/checkpoint-1000\n",
      "Configuration saved in ./saved/checkpoint-1000/config.json\n",
      "Model weights saved in ./saved/checkpoint-1000/pytorch_model.bin\n",
      "Deleting older checkpoint [saved/checkpoint-600] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 351\n",
      "  Batch size = 16\n",
      "100%|██████████| 240/240 [00:01<00:00, 140.05it/s]\n",
      "Saving model checkpoint to ./saved/checkpoint-1100\n",
      "Configuration saved in ./saved/checkpoint-1100/config.json\n",
      "Model weights saved in ./saved/checkpoint-1100/pytorch_model.bin\n",
      "Deleting older checkpoint [saved/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 351\n",
      "  Batch size = 16\n",
      "100%|██████████| 240/240 [00:01<00:00, 141.09it/s]\n",
      "Saving model checkpoint to ./saved/checkpoint-1200\n",
      "Configuration saved in ./saved/checkpoint-1200/config.json\n",
      "Model weights saved in ./saved/checkpoint-1200/pytorch_model.bin\n",
      "Deleting older checkpoint [saved/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 351\n",
      "  Batch size = 16\n",
      "100%|██████████| 240/240 [00:01<00:00, 140.76it/s]\n",
      "Saving model checkpoint to ./saved/checkpoint-1300\n",
      "Configuration saved in ./saved/checkpoint-1300/config.json\n",
      "Model weights saved in ./saved/checkpoint-1300/pytorch_model.bin\n",
      "Deleting older checkpoint [saved/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 351\n",
      "  Batch size = 16\n",
      "100%|██████████| 240/240 [00:01<00:00, 139.91it/s]\n",
      "Saving model checkpoint to ./saved/checkpoint-1400\n",
      "Configuration saved in ./saved/checkpoint-1400/config.json\n",
      "Model weights saved in ./saved/checkpoint-1400/pytorch_model.bin\n",
      "Deleting older checkpoint [saved/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 351\n",
      "  Batch size = 16\n",
      "100%|██████████| 240/240 [00:01<00:00, 142.18it/s]\n",
      "Saving model checkpoint to ./saved/checkpoint-1500\n",
      "Configuration saved in ./saved/checkpoint-1500/config.json\n",
      "Model weights saved in ./saved/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [saved/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 351\n",
      "  Batch size = 16\n",
      "100%|██████████| 240/240 [00:01<00:00, 143.42it/s]\n",
      "Saving model checkpoint to ./saved/checkpoint-1600\n",
      "Configuration saved in ./saved/checkpoint-1600/config.json\n",
      "Model weights saved in ./saved/checkpoint-1600/pytorch_model.bin\n",
      "Deleting older checkpoint [saved/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 351\n",
      "  Batch size = 16\n",
      "100%|██████████| 240/240 [00:01<00:00, 142.23it/s]\n",
      "Saving model checkpoint to ./saved/checkpoint-1700\n",
      "Configuration saved in ./saved/checkpoint-1700/config.json\n",
      "Model weights saved in ./saved/checkpoint-1700/pytorch_model.bin\n",
      "Deleting older checkpoint [saved/checkpoint-1300] due to args.save_total_limit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1314\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m                 if (\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
